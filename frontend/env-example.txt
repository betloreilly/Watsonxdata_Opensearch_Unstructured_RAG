# ===========================================
# RAG Chat UI - Environment Variables
# ===========================================
# Copy this file to .env.local in this folder and fill in your values.
# Do not commit .env or .env.local (they are gitignored).
#
# OpenSearch must be a managed cluster (e.g. watsonx.data). The Unstructured.io
# pipeline does not support local Docker OpenSearch.
#
# If Langflow runs in Docker with -p 7860:7860, use: LANGFLOW_URL=http://localhost:7860

# --- Langflow (required for chat) ---
# Create API key in Langflow: Settings (gear) → API Keys
LANGFLOW_URL=
LANGFLOW_FLOW_ID=
LANGFLOW_API_KEY=

# --- OpenSearch (managed cluster; for Unstructured ingestion, /api/semantic, and Langflow flow) ---
# Full URL to your OpenSearch cluster (trailing slash is optional; leading/trailing spaces are stripped)
OPENSEARCH_URL=
OPENSEARCH_USERNAME=
OPENSEARCH_PASSWORD=
INDEX_NAME=rag_demo
# Optional: set embedding dimension for index (1536=OpenAI, 384/768/1024=watsonx). Default 1536.
# EMBEDDING_DIMENSION=1536
# Optional: set OPENSEARCH_SSL_VERIFY=false to skip TLS verification for HTTPS (insecure; dev only).
# OPENSEARCH_SSL_VERIFY=false

# --- OpenAI (optional – for Langflow flow and/or semantic mode) ---
# Set in frontend/.env.local and in Langflow Global Variables if the flow uses OpenAI.
# OPENAI_API_KEY=
# OPENAI_EMBEDDING_MODEL=text-embedding-3-small
# OPENAI_LLM_MODEL=gpt-4o-mini

# --- watsonx.ai (optional – for Langflow flow) ---
# Set in frontend/.env.local and in Langflow Global Variables if the flow uses watsonx.
# WATSONX_API_KEY=
# WATSONX_PROJECT_ID=
# WATSONX_URL=
# WATSONX_LLM_MODEL=meta-llama/llama-3-1-8b
# WATSONX_EMBEDDING_MODEL=ibm/slate-125m-english-rtrvr-v2
